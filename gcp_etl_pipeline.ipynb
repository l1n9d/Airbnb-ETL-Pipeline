{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Write Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from typing import NamedTuple\n",
    "import csv\n",
    "from apache_beam.io.gcp.bigquery import WriteToBigQuery\n",
    "from google.cloud import bigquery\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Create a Pipeline Object with Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_options = PipelineOptions(\n",
    "    runner='DirectRunner',\n",
    "    project='demi001',\n",
    "    temp_location='gs://demistore01/tmp/',\n",
    "    staging_location='gs://demistore01/staging',\n",
    "    job_name='etl-pipeline',\n",
    "    machine_type='e2-standard-2',\n",
    "    flags=[],\n",
    "    num_workers=1,\n",
    "    max_num_workers=1,\n",
    "    region='us-central1',\n",
    "    save_main_session=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypipeline = beam.Pipeline(options=pipeline_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Read Data from GCS Bucket in the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/usercode/etl-pipeline-key.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_bucket = 'demistore01'\n",
    "csv_file_path = 'airbnb_data.csv'\n",
    "gcs_path = f'gs://{gcs_bucket}/{csv_file_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_data = (\n",
    "    mypipeline\n",
    "    | 'Read CSV' >> beam.io.ReadFromText(gcs_path, skip_header_lines=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8: Parse the Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirbnbData(NamedTuple):\n",
    "    id: str\n",
    "    name: str\n",
    "    host_id: str\n",
    "    host_name: str\n",
    "    neighbourhood_group: str\n",
    "    neighbourhood: str\n",
    "    latitude: str\n",
    "    longitude: str\n",
    "    room_type: str\n",
    "    price: str\n",
    "    minimum_nights: str\n",
    "    number_of_reviews: str\n",
    "    last_review: str\n",
    "    reviews_per_month: str\n",
    "    calculated_host_listings_count: str\n",
    "    availability_365: str\n",
    "    number_of_reviews_ltm: str\n",
    "    license: str\n",
    "    price_type: str = ''\n",
    "    neighborhood_avg_price: float = 0\n",
    "    price_usd: float = 0\n",
    "    lr_year: str = ''\n",
    "    lr_month: str = ''\n",
    "    lr_day: str = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = (\n",
    "    csv_data\n",
    "    | 'Parse CSV' >> beam.Map(lambda row: AirbnbData(*next(csv.reader([row]))))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 9: Define Data Validation Functions in the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = (\n",
    "    parsed_data\n",
    "    | 'Filter positive prices' >> beam.Filter(lambda row: int(row.price) >= 0)\n",
    "    | 'Filter abnormal coordinates' >> beam.Filter(\n",
    "        lambda row: (\n",
    "            -90.0 <= float(row.latitude) <= 90.0 and\n",
    "            -180.0 <= float(row.longitude) <= 180.0\n",
    "        )\n",
    "    )\n",
    "    | 'Filter non-null host IDs' >> beam.Filter(lambda row: row.host_id.strip() != '')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 10: Define Data Cleaning Functions in the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_data = (\n",
    "    filtered_data\n",
    "    | 'Remove duplicates' >> beam.Distinct()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_char_replaced = (\n",
    "    deduplicated_data\n",
    "    | 'Replace comma' >> beam.Map(lambda row: row._replace(**{'name': row.name.replace(',', '_')}))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_values(row):\n",
    "    return row._replace(\n",
    "        neighbourhood='not available' if row.neighbourhood in ('', None) else row.neighbourhood,\n",
    "        availability_365='0' if row.availability_365 in ('', None) else row.availability_365,\n",
    "        reviews_per_month='0' if row.reviews_per_month in ('', None) else row.reviews_per_month,\n",
    "        number_of_reviews_ltm='0' if row.number_of_reviews_ltm in ('', None) else row.number_of_reviews_ltm\n",
    "    )\n",
    "\n",
    "class ImputeValues(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        return [impute_values(element)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = (\n",
    "    special_char_replaced\n",
    "    | 'Impute values' >> beam.ParDo(ImputeValues())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 11: Define Data Enrichment Functions in the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_data = (\n",
    "    cleaned_data\n",
    "    | 'Classify PriceType' >> beam.Map(\n",
    "        lambda row: row._replace(price_type='economic' if int(row.price) < 50 else ('midrange' if 50 <= int(row.price) < 150 else 'luxury'))\n",
    "    )\n",
    "    | 'Convert to USD' >> beam.Map(\n",
    "        lambda row: row._replace(price_usd=float(row.price) * 0.66 )\n",
    "    )\n",
    "    | 'Extract date components' >> beam.Map(\n",
    "        lambda row: row._replace(\n",
    "            lr_year='',\n",
    "            lr_month='',\n",
    "            lr_day=''\n",
    "        ) if row.last_review in ('', None) else row._replace(\n",
    "            lr_year=int(datetime.strptime(row.last_review, '%Y-%m-%d').year),\n",
    "            lr_month=int(datetime.strptime(row.last_review, '%Y-%m-%d').month),\n",
    "            lr_day=int(datetime.strptime(row.last_review, '%Y-%m-%d').day)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 12: Perform Aggregation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_price_per_neighborhood = (\n",
    "    enriched_data\n",
    "    | 'KeyBy Neighborhood' >> beam.Map(lambda row: (row.neighbourhood, float(row.price)))\n",
    "    | 'GroupBy Neighborhood' >> beam.GroupByKey()\n",
    "    | 'Compute avg price' >> beam.Map(lambda kv: (kv[0], sum(kv[1]) / len(kv[1])))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_data_with_avg_price = (\n",
    "    enriched_data\n",
    "    | 'Add NeighborhoodAvgPrice' >> beam.Map(\n",
    "        lambda row, avg_price_dict: row._replace(\n",
    "            neighborhood_avg_price=round(avg_price_dict.get(row.neighbourhood, 0), 2)\n",
    "        ),\n",
    "        avg_price_dict=beam.pvalue.AsDict(avg_price_per_neighborhood)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 13: Create BigQuery Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"demi001.airbnb_ds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = bigquery.Dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.location = \"US\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.create_dataset(dataset, exists_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 14: Upload Final Data to BigQuery Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table_spec = 'demi001:airbnb_ds.airbnb_tb'\n",
    "gcs_temp_location = 'gs://demistore01/bigquery_temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<apache_beam.io.gcp.bigquery.WriteResult at 0x76dff7091eb0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(enriched_data_with_avg_price\n",
    "    | 'Convert to Dict' >> beam.Map(lambda row: row._asdict())\n",
    "    | 'Write to BigQuery' >> WriteToBigQuery(\n",
    "        output_table_spec,\n",
    "        schema='SCHEMA_AUTODETECT',\n",
    "        create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
    "        custom_gcs_temp_location=gcs_temp_location)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 15: Execute the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class '__main__.AirbnbData'>' in '[10]: Remove duplicates/Group/GroupByKey'. \n",
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class '__main__.AirbnbData'>' in '[10]: Remove duplicates/Group/GroupByKey'. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = mypipeline.run()\n",
    "result.wait_until_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "state = result.state\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 16: Create Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_id = \"demi001.airbnb_ds.airbnb_analysis_vw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_ref = bigquery.Table(view_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_ref.view_query = \"\"\"\n",
    "SELECT\n",
    "  neighbourhood,\n",
    "  price_type,\n",
    "  ROUND(AVG(price), 2) AS avg_price,\n",
    "  ROUND(MIN(price), 2) AS min_price,\n",
    "  ROUND(MAX(price), 2) AS max_price,\n",
    "  MIN(neighborhood_avg_price) AS min_neighbourhood_avg_price,\n",
    "  MAX(neighborhood_avg_price) AS max_neighbourhood_avg_price\n",
    "FROM airbnb_ds.airbnb_tb\n",
    "GROUP BY neighbourhood, price_type \n",
    "ORDER BY neighbourhood, price_type;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = client.create_table(view_ref , exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 17: Validate the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  f0_  |\n",
      "+-------+\n",
      "| 23171 |\n",
      "+-------+\n"
     ]
    }
   ],
   "source": [
    "!bq query --use_legacy_sql=false \"SELECT count(*) FROM airbnb_ds.airbnb_tb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-----------+-----------+-----------+-----------------------------+-----------------------------+\n",
      "| neighbourhood | price_type | avg_price | min_price | max_price | min_neighbourhood_avg_price | max_neighbourhood_avg_price |\n",
      "+---------------+------------+-----------+-----------+-----------+-----------------------------+-----------------------------+\n",
      "| Banyule       | economic   |     39.06 |      15.0 |      49.0 |                      158.01 |                      158.01 |\n",
      "| Banyule       | luxury     |     270.9 |     150.0 |    1200.0 |                      158.01 |                      158.01 |\n",
      "| Banyule       | midrange   |     95.36 |      50.0 |     149.0 |                      158.01 |                      158.01 |\n",
      "| Bayside       | economic   |     34.33 |      25.0 |      40.0 |                      380.25 |                      380.25 |\n",
      "| Bayside       | luxury     |    515.66 |     150.0 |   11429.0 |                      380.25 |                      380.25 |\n",
      "| Bayside       | midrange   |    101.06 |      50.0 |     149.0 |                      380.25 |                      380.25 |\n",
      "| Boroondara    | economic   |     36.98 |      13.0 |      49.0 |                      383.81 |                      383.81 |\n",
      "| Boroondara    | luxury     |    719.09 |     150.0 |  104983.0 |                      383.81 |                      383.81 |\n",
      "| Boroondara    | midrange   |     93.79 |      50.0 |     149.0 |                      383.81 |                      383.81 |\n",
      "| Brimbank      | economic   |     39.38 |      25.0 |      49.0 |                       122.6 |                       122.6 |\n",
      "+---------------+------------+-----------+-----------+-----------+-----------------------------+-----------------------------+\n"
     ]
    }
   ],
   "source": [
    "!bq query --use_legacy_sql=false \"SELECT * FROM airbnb_ds.airbnb_analysis_vw LIMIT 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 20: Validating the Pipeline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  f0_  |\n",
      "+-------+\n",
      "| 23171 |\n",
      "+-------+\n"
     ]
    }
   ],
   "source": [
    "!bq query --use_legacy_sql=false \"SELECT count(*) FROM airbnb_ds_new.airbnb_tb_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-----------+-----------+-----------+-----------------------------+-----------------------------+\n",
      "| neighbourhood | price_type | avg_price | min_price | max_price | min_neighbourhood_avg_price | max_neighbourhood_avg_price |\n",
      "+---------------+------------+-----------+-----------+-----------+-----------------------------+-----------------------------+\n",
      "| Banyule       | economic   |     39.06 |      15.0 |      49.0 |                      158.01 |                      158.01 |\n",
      "| Banyule       | luxury     |     270.9 |     150.0 |    1200.0 |                      158.01 |                      158.01 |\n",
      "| Banyule       | mid-range  |     95.36 |      50.0 |     149.0 |                      158.01 |                      158.01 |\n",
      "| Bayside       | economic   |     34.33 |      25.0 |      40.0 |                      380.25 |                      380.25 |\n",
      "| Bayside       | luxury     |    515.66 |     150.0 |   11429.0 |                      380.25 |                      380.25 |\n",
      "| Bayside       | mid-range  |    101.06 |      50.0 |     149.0 |                      380.25 |                      380.25 |\n",
      "| Boroondara    | economic   |     36.98 |      13.0 |      49.0 |                      383.81 |                      383.81 |\n",
      "| Boroondara    | luxury     |    719.09 |     150.0 |  104983.0 |                      383.81 |                      383.81 |\n",
      "| Boroondara    | mid-range  |     93.79 |      50.0 |     149.0 |                      383.81 |                      383.81 |\n",
      "| Brimbank      | economic   |     39.38 |      25.0 |      49.0 |                       122.6 |                       122.6 |\n",
      "+---------------+------------+-----------+-----------+-----------+-----------------------------+-----------------------------+\n"
     ]
    }
   ],
   "source": [
    "!bq query --use_legacy_sql=false \"SELECT * FROM airbnb_ds_new.airbnb_analysis_vw_new LIMIT 10\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
